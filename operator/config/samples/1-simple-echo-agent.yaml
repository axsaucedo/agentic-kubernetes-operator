---
# Sample 1: Simple Echo Agent with MCP Server
# A single agent with access to an echo MCP tool and a ModelAPI proxy to local Ollama
# Deploy: kubectl apply -f 1-simple-echo-agent.yaml

apiVersion: v1
kind: Namespace
metadata:
  name: agentic-simple
  labels:
    app.kubernetes.io/part-of: agentic-sample-simple

---
# ModelAPI: LiteLLM proxy to local Ollama (via Docker Desktop host)
apiVersion: ethical.institute/v1alpha1
kind: ModelAPI
metadata:
  name: simple-modelapi
  namespace: agentic-simple
spec:
  mode: Proxy
  proxyConfig:
    env:
    - name: OPENAI_API_KEY
      value: "sk-test"
    - name: LITELLM_LOG
      value: "WARN"
    - name: LITELLM_MODEL_LIST
      value: "ollama/smollm2:135m"
    - name: OLLAMA_BASE_URL
      value: "http://host.docker.internal:11434"

---
# MCPServer: Echo tool for testing
apiVersion: ethical.institute/v1alpha1
kind: MCPServer
metadata:
  name: simple-echo-mcp
  namespace: agentic-simple
spec:
  type: python-runtime
  config:
    mcp: "test-mcp-echo-server"
    env:
    - name: LOG_LEVEL
      value: "INFO"
  resources:
    requests:
      memory: "128Mi"
      cpu: "100m"
    limits:
      memory: "256Mi"
      cpu: "500m"

---
# Agent: Simple echo agent with MCP tool access
apiVersion: ethical.institute/v1alpha1
kind: Agent
metadata:
  name: simple-agent
  namespace: agentic-simple
spec:
  modelAPI: simple-modelapi
  mcpServers:
  - simple-echo-mcp
  config:
    description: "A simple echo agent for testing"
    instructions: |
      You are a helpful assistant with access to an echo tool.
      When asked to echo something, use the echo tool to return the message.
      Always provide clear and concise responses.
    env:
    - name: MODEL_NAME
      value: "smollm2:135m"
    agenticLoop:
      maxSteps: 5
      enableTools: true
      enableDelegation: false
  agentNetwork:
    expose: true
    access: []
  replicas: 1
  resources:
    requests:
      memory: "256Mi"
      cpu: "200m"
    limits:
      memory: "512Mi"
      cpu: "1000m"
